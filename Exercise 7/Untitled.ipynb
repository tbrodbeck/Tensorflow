{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as  tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_gradients_and_rewards(gradients, rewards, discount_factor, gradient_list_pointer):\n",
    "    seq_length = len(rewards)\n",
    "    #compute the respective reward values\n",
    "    rewards = np.asarray(rewards)\n",
    "    last_reward = 0\n",
    "    for i in np.arange(seq_length):\n",
    "        index_from_end = (i+1)*(-1)\n",
    "        rewards[index_from_end] = (discount_factor * last_reward) + rewards[index_from_end]\n",
    "        last_reward = rewards[index_from_end]\n",
    "    rewards -= np.mean(rewards)\n",
    "    rewards = rewards / np.std(rewards)\n",
    "\n",
    "\n",
    "    for i in np.arange(seq_length):\n",
    "        for gradient_index in np.arange(len(gradients[i])):\n",
    "            gradients[i][gradient_index] = gradients[i][gradient_index] * rewards[i]\n",
    "            #print(gradients[i][gradient_index])\n",
    "\n",
    "    variable_length = len(gradients[0])\n",
    "    summed_gradient_list = []\n",
    "    for i in np.arange(variable_length):\n",
    "        summed_gradient_list.append(np.zeros(np.shape(gradients[0][i])))\n",
    "        for j in np.arange(seq_length):\n",
    "            summed_gradient_list[i] += gradients[j][i]\n",
    "\n",
    "    grad_dict = {}\n",
    "    for i in np.arange(len(gradient_list_pointer)):\n",
    "        grad_dict[gradient_list_pointer[i]] = summed_gradient_list[i]\n",
    "    return grad_dict, rewards\n",
    "\n",
    "    grad_dict = {}\n",
    "    for i, placeholder in enumerate(gradient_list_pointer):\n",
    "        grad_dict[placeholder] = gradients[i]\n",
    "    return grad_dict, rewards\n",
    "\n",
    "####parameters####\n",
    "episodes = 500\n",
    "episode_length = 200\n",
    "learning_rate = 0.01\n",
    "discount_factor = 0.97\n",
    "batch_size = 15\n",
    "show_sample_factor = 500\n",
    "\n",
    "#### the graph ####\n",
    "x = tf.placeholder(tf.float32, shape = (1,4))\n",
    "#FFLayer\n",
    "w01 = tf.Variable(tf.random_normal(shape = (4,20), stddev = 0.02))\n",
    "b01 = tf.Variable(tf.zeros(shape = (1,20)))\n",
    "l01 = tf.nn.relu(tf.add(tf.matmul(x,w01), b01))\n",
    "\n",
    "## Outlayer\n",
    "w02 = tf.Variable(tf.random_normal(shape = (20,1), stddev = 0.02))\n",
    "b02 = tf.Variable(tf.zeros(shape = (1,1)))\n",
    "prob01 = tf.nn.sigmoid(tf.add(tf.matmul(l01,w02), b02))\n",
    "prob02 = tf.subtract(1.0, prob01)\n",
    "\n",
    "probs = tf.log(tf.concat([prob01, prob02],1))\n",
    "\n",
    "#logs\n",
    "action = tf.multinomial(probs,1)[0][0]\n",
    "\n",
    "log_likelihood = probs[:, tf.to_int32(action)]\n",
    "\n",
    "### from Lukas code\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "# Compute gradients, returns a list of gradient variable tuples\n",
    "gradients_and_variables = optimizer.compute_gradients(log_likelihood)\n",
    "\n",
    "# Extract gradients and inverse the sign of gradients\n",
    "# (compute_gradients returns inverted gradients for minimization)\n",
    "gradients = [gradient_and_variable[0] * -1 for gradient_and_variable in gradients_and_variables]\n",
    "\n",
    "# Retrieve and modify the gradients from within a session\n",
    "# Create placeholders for modified gradients\n",
    "gradient_placeholders = []\n",
    "for gradient in gradients:\n",
    "    gradient_placeholders.append(tf.placeholder(tf.float32, gradient.shape))\n",
    "\n",
    "# Apply gradients\n",
    "trainable_variables = tf.trainable_variables()\n",
    "training_step = optimizer.apply_gradients(zip(gradient_placeholders, trainable_variables))\n",
    "\n",
    "#start session, deploy graph\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    #get ai_gym environment\n",
    "    env = gym.make('CartPole-v0')\n",
    "\n",
    "    #lists for buffering results\n",
    "    gradient_dictionary_list = []\n",
    "    success_list = []\n",
    "    #go over all the episodes\n",
    "    for episode in np.arange(episodes):\n",
    "        observation = env.reset()\n",
    "        #reset the buffers\n",
    "        gradient_list = []\n",
    "        reward_list = []\n",
    "        #go through all the steps\n",
    "        for step in np.arange(episode_length):\n",
    "            #get observation and compute action\n",
    "            observation = observation[np.newaxis]\n",
    "            selected_action, extracted_gradient= session.run([action, gradients], feed_dict = {x: observation})\n",
    "            observation, reward, done, info = env.step(selected_action)\n",
    "            #keep track of rewards and gradients\n",
    "            gradient_list.append(extracted_gradient)\n",
    "            reward_list.append(reward)\n",
    "\n",
    "            #check whether we should show this episode\n",
    "            if episode%show_sample_factor == 0:\n",
    "                env.render()\n",
    "            #break loop when we are done\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # get weighted gradients and discount the rewards\n",
    "        gradient_dictionary, discounted_rewards = compute_gradients_and_rewards(gradient_list, reward_list, discount_factor, gradient_placeholders)\n",
    "        gradient_dictionary_list.append(gradient_dictionary)\n",
    "        success_list.append(len(discounted_rewards))\n",
    "\n",
    "        #only update the model when we have enough steps for a full batch of updating\n",
    "        if episode % batch_size == 0:\n",
    "            for feed_dictionary in gradient_dictionary_list:\n",
    "                _ = session.run(training_step, feed_dict = feed_dictionary)\n",
    "            gradient_dictionary_list = []\n",
    "\n",
    "    #plot results\n",
    "    print('hallo')\n",
    "    plt.plot(np.asarray(success_list))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
