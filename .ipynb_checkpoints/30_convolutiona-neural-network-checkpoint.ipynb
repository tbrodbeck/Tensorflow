{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import cifar_helper\n",
    "\n",
    "cifar = cifar_helper.CIFAR(\"./cifar_10_batches_py/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label = next(cifar.get_training_batch(12))\n",
    "print(np.shape(images))\n",
    "print(np.shape(images))\n",
    "\n",
    "# @TODO labels anzeigen\n",
    "fig, axes = plt.subplots(3, 4)\n",
    "for i, ax in enumerate(np.reshape(axes, [-1])):\n",
    "    ax.imshow(images[i])\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.set_title(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an idea of the complexity of the network structure, think about the following two questions: How many neurons are simulated? \n",
    "\n",
    "There are 16*32*32 + 16*16*16 + 32*16*16 + 32*8*8 + 512 + 10 = 31242 Neurons.\n",
    "\n",
    "How many degrees of freedom (weights) does the network have? \n",
    "\n",
    "16*5*5*3 + 16 + 32*3*3*16 + 32*8*8*512 + 32*8*8 + 512 * 10 + 10\n",
    "\n",
    "Of many ï¬‚oating-point operations are necessary for a forward pass of the network? (Write down your answer!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of our minibatch, the amount of samples we train on in each training instance\n",
    "minibatch_size = 12\n",
    "\n",
    "kernelsize_l1 = 5\n",
    "kernelsize_l3 = 3\n",
    "\n",
    "# defining input x as placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(minibatch_size, 32, 32, 3))\n",
    "\n",
    "# LAYER ONE\n",
    "# defining kernel of layer 1\n",
    "kernel_l1 = tf.Variable(tf.truncated_normal(shape=(kernelsize_l1, kernelsize_l1, 3, 16), stddev=0.1))\n",
    "\n",
    "# apply 1st layer convolution\n",
    "featuremap_l1 = tf.nn.conv2d(x, kernel_l1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "# define bias layer one\n",
    "bias_l1 = tf.Variable(tf.truncated_normal(shape=(32, 32, 16), stddev=0.1))\n",
    "\n",
    "# Calculate neuron outputs by applying the activation function\n",
    "activation_l1 = tf.nn.tanh(featuremap_l1 + bias_l1)\n",
    "\n",
    "# LAYER TWO\n",
    "# apply max pooling to outputs\n",
    "pooling_l2 = tf.nn.max_pool(activation_l1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "# LAYER THREE\n",
    "# defining kernel of layer 3\n",
    "kernel_l3 = tf.Variable(tf.truncated_normal(shape=(kernelsize_l3, kernelsize_l3, 16, 32), stddev=0.1))\n",
    "\n",
    "# apply 3rd layer convolution\n",
    "featuremap_l3 = tf.nn.conv2d(pooling_l2, kernel_l3, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "# define bias layer three\n",
    "bias_l3 = tf.Variable(tf.truncated_normal(shape=(16, 16, 32), stddev=0.1))\n",
    "\n",
    "# Calculate neuron outputs by applying the activation function\n",
    "activation_l3 = tf.nn.tanh(featuremap_l3 + bias_l3)\n",
    "\n",
    "# LAYER FOUR\n",
    "# apply max pooling to outputs\n",
    "pooling_l4 = tf.nn.max_pool(activation_l3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "# LAYER FIVE\n",
    "# we reshape the feature maps \n",
    "reshape_l4 = tf.reshape(pooling_l4, (minibatch_size, 8*8*32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
